= image:osp.png[float="left" width=200 ] TriXX: Step by step demo how to run including Kafka and kSqlDB =
Author: Peter Ramm ( Peter.Ramm@ottogroup.com )
:Author Initials: PR
:toc:
:toclevels: 4
:icons:
:imagesdir: ./images
:numbered:
:sectnumlevels: 6
:homepage: https://www.osp.de
:title-logo-image: osp.png

Last actualization: 2021-06-09

== Preconditions ==
- A running local Oracle database with an user to observe, in our case user="panorama_test"

TIP: Use real physical IP-addresses for Kafka configuration, not 'localhost'. Because Kafka uses this addresses also from inside the container where 'localhost' has a different content.

== Prepare Kafka ==
=== Set your local host IP address ===
----
export IP_ADDRESS=192.168.178.34
----

=== Run Kafka container ===
In our case an own Docker image that combines Zookeeper and Kafka in one image
----
docker run --rm \
  -p 2181:2181 \
  -p 9092:9092 \
  -e KAFKA_ADVERTISED_LISTENERS=LISTENER_EXT://$IP_ADDRESS:9092,LISTENER_INT://localhost:9093 \
  git.osp-dd.de:5005/main/trixx/kafka-compact
----

=== Create topic ===
run the command within in the just started Kafka Docker container ("docker exec -ti <container-ID> bash"):
----
$KAFKA_HOME/bin/kafka-topics.sh --create --topic hugo --partitions 4 --zookeeper localhost:2181 --replication-factor 1
----

=== Create Consumer for topic ===
run the command within in the just started Kafka Docker container ("docker exec -ti <container-ID> bash"):
----
$KAFKA_HOME/bin/kafka-console-consumer.sh --topic=hugo --bootstrap-server=$IP_ADDRESS:9092 --isolation-level=read_committed
----


== Prepare TriXX application ==

=== Create config file run_config.yml ===
----
cat <<EOF >run_config.yml
################################

# Log level for application (debug, info, warn, error)
LOG_LEVEL: debug

# Type of used database (SQLITE, ORACLE)
DB_TYPE: ORACLE

# Username of TriXX schema in database
DB_USER: trixx_demo

# Password of DB_USER, also used as password of user 'admin' for GUI logon.
DB_PASSWORD: trixx_demo

# Database-URL for JDBC Connect: Example for Oracle: "MY_TNS_ALIAS" or "machine:port/service"
DB_URL: $IP_ADDRESS:1521/ORCLPDB1

# Comma separated list of seed brokers for Kafka logon, "/dev/null" for mocking Kafka connection
KAFKA_SEED_BROKER: $IP_ADDRESS:9092

################################
EOF
----

=== Create DB-User for Trixx ===
----
docker run --rm \
  -e RUN_CONFIG=/etc/run_config.yml \
  -e DB_SYS_PASSWORD=oracle \
  -v $PWD/run_config.yml:/etc/run_config.yml \
  git.osp-dd.de:5005/main/trixx:master bundle exec rake ci_preparation:create_user
----

=== Run TriXX Docker container ===
----
docker run --rm \
  -e RUN_CONFIG=/etc/run_config.yml \
  -v $PWD/run_config.yml:/etc/run_config.yml \
  -p8080:8080 \
  git.osp-dd.de:5005/main/trixx:master
----

== Prepare test case ==

=== Create a table to observe for test user ===
----
echo "
-- Remove possibly existing objects
BEGIN
  FOR Rec IN (SELECT 1 FROM User_Tables WHERE Table_Name = 'HUGO') LOOP
    EXECUTE IMMEDIATE 'DROP TABLE HUGO';
  END LOOP;
  FOR Rec IN (SELECT 1 FROM User_Sequences WHERE Sequence_Name = 'HUGO_SEQ') LOOP
    EXECUTE IMMEDIATE 'DROP SEQUENCE HUGO_SEQ';
  END LOOP;
END;
/

CREATE TABLE Panorama_Test.Hugo (
       ID          NUMBER PRIMARY KEY,
       Name        VARCHAR2(30),
       Start_Date  DATE);
CREATE SEQUENCE Hugo_Seq;
GRANT SELECT ON Hugo TO Public;
GRANT FLASHBACK ON Hugo TO Public;
" | sqlplus panorama_test/panorama_test@$IP_ADDRESS:1521/ORCLPDB1
----

=== Generate permanent changes on panorama_test.Hugo ===
----
echo "
  BEGIN
    LOOP
      INSERT INTO Hugo (ID, Name, Start_Date) VALUES (Hugo_Seq.NextVal, 'Name '||Hugo_Seq.Currval, SYSDATE);
      COMMIT;
      DBMS_SESSION.SLEEP(1);
    END LOOP;
  END;
/
" | sqlplus panorama_test/panorama_test@localhost:1521/ORCLPDB1
----


=== Configure Trixx by GUI to catch changes on table panorama_test.Hugo ===
- Open TriXX application in browser: http://localhost:8080
- first login with user "admin" and passwort of DB-user for TriXX
- create your own personal user, choose a DB-user for authentication
- authenticate user for a schema including deployment grant
- Logout as 'admin', connect with this personal user
- Configure events for table panorama_test.Hugo
- generate triggers
- watch what happens in Kafka consumer and ksqlDB

== Prepare ksqlDB ==
=== Run ksqlDB Docker containers ===


==== create docker-compose.yml ====
----
cat <<EOF >docker-compose.yml
---
version: '2'

services:
  ksqldb-server:
    image: confluentinc/ksqldb-server:0.11.0
    hostname: ksqldb-server
    container_name: ksqldb-server
    ports:
      - "8088:8088"
    environment:
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: $IP_ADDRESS:9092
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"

  ksqldb-cli:
    image: confluentinc/ksqldb-cli:0.11.0
    container_name: ksqldb-cli
    depends_on:
      - ksqldb-server
    entrypoint: /bin/sh
    tty: true
EOF
----

==== Start ksqlDB ====
----
docker-compose up
----

=== Connect to ksqlDB CLI ===
----
docker exec -it ksqldb-cli ksql http://ksqldb-server:8088
----

=== Create stream from topic in ksqlDB CLI ===
----
CREATE STREAM hugo_stream (msg_key VARCHAR KEY,
                           id INTEGER,
                           schema VARCHAR,
                           tablename VARCHAR,
                           operation VARCHAR,
                           timestamp VARCHAR,
                           new STRUCT<NAME VARCHAR, ID INTEGER, START_DATE VARCHAR>)
  WITH (kafka_topic='hugo', value_format='JSON');
----

=== Select from stream in ksqlDB CLI ===
----
SELECT id, schema, tablename, operation, timestamp, new->NAME,
  new->ID, new->Start_Date FROM hugo_stream EMIT CHANGES;
----


