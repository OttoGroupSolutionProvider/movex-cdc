= image:osp.png[float="left" width=200 ] MOVEX Change Data Capture: Step by step demo how to run including Kafka and kSqlDB =
Author: Peter Ramm ( Peter.Ramm@ottogroup.com )
:Author Initials: PR
:toc:
:toclevels: 4
:icons:
:imagesdir: ./images
:numbered:
:sectnumlevels: 6
:homepage: https://www.osp.de
:title-logo-image: osp.png

Last actualization: 2021-12-06

== Preconditions ==
- A running local Oracle database with an existing user to observe

TIP: Use real physical IP-addresses for Kafka configuration, not 'localhost'. Because Kafka uses this addresses also from inside the container where 'localhost' has a different content.

== Prepare your local host valid IP address, DB URL and user credentials ==
----
export IP_ADDRESS=192.168.178.34
export DB_URL=$IP_ADDRESS:1521/ORCLPDB1
export MOVEX_DB_USER=movex
export MOVEX_DB_PASSWORD=movex
export DB_SYS_PASSWORD=oracle
export SOURCE_DB_USER=panorama_test
export SOURCE_DB_PASSWORD=panorama_test
----



== Prepare Kafka ==

=== Run Kafka container ===
We use an own Docker image that combines Zookeeper and Kafka in one image
----
docker run --rm \
  -p 2181:2181 \
  -p 9092:9092 \
  -e KAFKA_ADVERTISED_LISTENERS=LISTENER_EXT://$IP_ADDRESS:9092,LISTENER_INT://localhost:9093 \
  registry.gitlab.com/otto-group-solution-provider/movex-cdc/kafka-compact:3.0.0
----

=== Create the Kafka topic ===
Run the command within in the just started Kafka Docker container ("docker exec -ti <container-ID> bash"):
----
$KAFKA_HOME/bin/kafka-topics.sh --create --topic hugo --partitions 4 --bootstrap-server $IP_ADDRESS:9092 --replication-factor 1
----

=== Create a consumer process for the topic ===
Run the command within in the just started Kafka Docker container ("docker exec -ti <container-ID> bash"):
----
$KAFKA_HOME/bin/kafka-console-consumer.sh --topic=hugo --bootstrap-server=$IP_ADDRESS:9092 --isolation-level=read_committed
----

== Prepare the MOVEX Change Data Capture application ==

=== Create config file run_config.yml ===
----
cat <<EOF >run_config.yml
################################

# Log level for application (debug, info, warn, error)
LOG_LEVEL: debug

# Type of used database (SQLITE, ORACLE)
DB_TYPE: ORACLE

# Username of TriXX schema in database
DB_USER: $MOVEX_DB_USER

# Password of DB_USER, also used as password of user 'admin' for GUI logon.
DB_PASSWORD: $MOVEX_DB_PASSWORD

# Database-URL for JDBC Connect: Example for Oracle: "MY_TNS_ALIAS" or "machine:port/service"
DB_URL: $DB_URL

# Comma separated list of seed brokers for Kafka logon, "/dev/null" for mocking Kafka connection
KAFKA_SEED_BROKER: $IP_ADDRESS:9092

################################
EOF
----

=== Create DB-User for background services of MOVEX CDC ===
----
docker run --rm \
  -e RUN_CONFIG=/etc/run_config.yml \
  -e DB_SYS_PASSWORD=$DB_SYS_PASSWORD \
  -v $PWD/run_config.yml:/etc/run_config.yml \
  registry.gitlab.com/otto-group-solution-provider/movex-cdc:master bundle exec rake ci_preparation:create_user
----

=== Run MOVEX CDC Docker container ===
----
docker run --rm \
  -e RUN_CONFIG=/etc/run_config.yml \
  -v $PWD/run_config.yml:/etc/run_config.yml \
  -p8080:8080 \
  registry.gitlab.com/otto-group-solution-provider/movex-cdc:master
----

== Prepare test case ==

=== Create a table to observe for test user ===
----
echo "
-- Remove possibly existing objects
BEGIN
  FOR Rec IN (SELECT 1 FROM User_Tables WHERE Table_Name = 'HUGO') LOOP
    EXECUTE IMMEDIATE 'DROP TABLE HUGO';
  END LOOP;
  FOR Rec IN (SELECT 1 FROM User_Sequences WHERE Sequence_Name = 'HUGO_SEQ') LOOP
    EXECUTE IMMEDIATE 'DROP SEQUENCE HUGO_SEQ';
  END LOOP;
END;
/

CREATE TABLE Hugo (
       ID          NUMBER PRIMARY KEY,
       Name        VARCHAR2(30),
       Start_Date  DATE);
CREATE SEQUENCE Hugo_Seq;
GRANT SELECT ON Hugo TO $MOVEX_DB_USER;
GRANT FLASHBACK ON Hugo TO $MOVEX_DB_USER;
" | sqlplus $SOURCE_DB_USER/$SOURCE_DB_PASSWORD@$DB_URL
----

=== Generate permanent changes on the table to observe ===
----
echo "
  BEGIN
    LOOP
      INSERT INTO Hugo (ID, Name, Start_Date) VALUES (Hugo_Seq.NextVal, 'Name '||Hugo_Seq.Currval, SYSDATE);
      COMMIT;
      DBMS_SESSION.SLEEP(1);
    END LOOP;
  END;
/
" | sqlplus $SOURCE_DB_USER/$SOURCE_DB_PASSWORD@$DB_URL
----


=== Configure MOVEX CDC by GUI to catch changes on table panorama_test.Hugo ===
- Open application in browser: `http://localhost:8080`
- first login with user "admin" and passwort of the MOVEX DB user
- create your own personal application user, choose an existing DB-user for authentication
- authenticate user for a schema including deployment grant
- Logout as 'admin', connect with this personal user
- Configure events to observe for a table
- deploy the generated triggers
- watch what happens in Kafka consumer

== Prepare ksqlDB ==
=== Run ksqlDB Docker containers ===


==== create docker-compose.yml ====
----
cat <<EOF >docker-compose.yml
---
version: '2'

services:
  ksqldb-server:
    image: confluentinc/ksqldb-server:0.11.0
    hostname: ksqldb-server
    container_name: ksqldb-server
    ports:
      - "8088:8088"
    environment:
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: $IP_ADDRESS:9092
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"

  ksqldb-cli:
    image: confluentinc/ksqldb-cli:0.11.0
    container_name: ksqldb-cli
    depends_on:
      - ksqldb-server
    entrypoint: /bin/sh
    tty: true
EOF
----

==== Start ksqlDB ====
----
docker-compose up
----

=== Connect to ksqlDB CLI ===
----
docker exec -it ksqldb-cli ksql http://ksqldb-server:8088
----

=== Create stream from topic in ksqlDB CLI ===
----
CREATE STREAM hugo_stream (msg_key VARCHAR KEY,
                           id INTEGER,
                           schema VARCHAR,
                           tablename VARCHAR,
                           operation VARCHAR,
                           timestamp VARCHAR,
                           new STRUCT<NAME VARCHAR, ID INTEGER, START_DATE VARCHAR>)
  WITH (kafka_topic='hugo', value_format='JSON');
----

=== Select from stream in ksqlDB CLI ===
----
SELECT id, schema, tablename, operation, timestamp, new->NAME,
  new->ID, new->Start_Date FROM hugo_stream EMIT CHANGES;
----


